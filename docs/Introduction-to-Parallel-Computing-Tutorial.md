# 要約
このチュートリアルは，"Livermore Computing Getting Started "ワークショップの最初のチュートリアルです．このチュートリアルは，後続のチュートリアルへの導入として，並列コンピューティングという広範かつ広範なトピックの簡単な概要を提供することを目的としています．そのため，並列コンピューティングのごく基本的な部分をカバーしており，このテーマに慣れてきたばかりで，このワークショップの他のチュートリアルの1つ以上に参加する予定の人を対象としています．並列プログラミングを詳しく説明することは意図していませんが，それにはかなりの時間が必要となります．このチュートリアルでは，まず，並列コンピューティングとは何か，どのように使われるのか，という議論から始まり，続いて，並列コンピューティングに関連する概念や用語について説明します．続いて，並列メモリ・アーキテクチャとプログラミング・モデルのトピックを取り上げます．これらのトピックに続いて，並列プログラムの設計と実行に関する複雑な問題について，一連の実践的な議論が行われます．最後に，簡単なシリアル・プログラムを並列化するためのいくつかの例を挙げて締めくくります．また，参考文献も掲載していますので，自習にも最適です．

# 並列計算の概要
## 並列計算とは？
### 直列計算
従来，ソフトウェアは直列計算のために書かれてきました．
- 問題は離散的な一連の命令に分割されます．
- 命令は次々に実行される．
- 1台のプロセッサで実行される．
- どの時点でも1つの命令しか実行できない．
![serialproblem.gif](/philosophers/serialproblem.gif)
例
![serialproblem2.gif](/philosophers/serialproblem2.gif)

### 並列計算
並列計算とは，簡単に言えば，計算問題を解決するために複数の計算機資源を同時に使用することです．
- 問題は，同時に解くことができる個別のパーツに分割される．
- 各パーツはさらに一連の命令に分割されます．
- 各パーツの命令は，異なるプロセッサ上で同時に実行される．
- 全体的な制御調整メカニズムを採用する．
![parallelproblem.gif](/philosophers/parallelproblem.gif)
例
![parallelproblem2.gif](/philosophers/parallelproblem2.gif)

- 計算問題は以下のことが可能でなければなりません．
  - 同時に解くことができる個別の作業に分解されていること．
  - 複数のプログラム命令を任意のタイミングで実行できること．
  - 複数の計算資源を用いた方が，単一の計算資源を用いた場合よりも短時間で解けること．

- 計算機資源は，通常，以下のようなものです．
  - 複数のプロセッサコアを持つ1台のコンピュータ．
  - ネットワークで接続された任意の台数の計算機．

### 並列コンピュータ
- 今日，事実上すべてのスタンドアロンコンピュータは，ハードウェアの観点から並列化されています．
  - 複数の機能ユニット（L1キャッシュ，L2キャッシュ，ブランチ，プリフェッチ，デコード，浮動小数点，グラフィックスプロセッシング（GPU），整数など）．
  - 複数の実行ユニットコア
  - 複数のハードウェアスレッド
![bgqcomputechip.jpeg](/philosophers/bgqcomputechip.jpeg)
IBM BG/Q Compute Chip with 18 cores (PU) and 16 L2 Cache units (L2)

- ネットワークは，複数の独立したコンピュータ（ノード）を接続して，より大きな並列コンピュータ・クラスターを構成します．
![nodesnetwork.gif](/philosophers/nodesnetwork.gif)

- 例えば，下の図はLLNLの典型的な並列コンピュータクラスタを示しています．
  - 各計算ノードは，それ自体がマルチプロセッサの並列コンピュータです．
  - 複数の計算ノードが Infiniband ネットワークで結ばれています．
  - 同じくマルチプロセッサを搭載した特殊用途のノードは，他の目的に使用されます．
![parallelcomputer1.gif](/philosophers/parallelcomputer1.gif)

- 世界の大型並列コンピュータ（スーパーコンピュータ）の大半は，一握りの（ほとんど）有名ベンダーが製造するハードウェアのクラスターです．
Source: Top500.org

## 並列計算を使う理由
### 現実の世界は非常に複雑である
- 自然界では，多くの複雑で相互に関連した事象が，時間的な順序の中で，同時に起こっています．
- 直列計算と比較して，並列計算は，複雑な現実世界の現象をモデル化し，シミュレーションし，理解するのに適しています．
- 例えば，これらをシリアルでモデリングすることを想像してみてください．

### 主な理由
#### 時間とお金の節約
- 理論的には，より多くのリソースを投入することで，タスクの完了までの時間を短縮し，コストを削減することができます．
- 並列コンピュータは，安価な汎用部品で構成することができます．

#### より大きな，より複雑な問題を解決する
- 多くの問題は非常に大きく，複雑であるため，特にコンピュータのメモリが限られている場合には，シリアルプログラムで解決することは現実的ではなく，不可能です．
- 例: [グランドチャレンジ問題](https://en.wikipedia.org/wiki/Grand_Challenges)では，ペタフロップスやペタバイトのコンピューティングリソースが必要となります．
- 例: ウェブ検索エンジン毎秒数百万件のトランザクションを処理するデータベース．

#### 並行性の提供
- 1つのコンピュートリソースは，同時に1つのことしかできません．複数のコンピュートリソースは，同時に多くのことを行うことができます．
- 例: コラボレーションネットワークは，世界中の人々が "バーチャル"に集まり，仕事をすることができるグローバルな場を提供します．

#### 地域外のリソースを活用する
- ローカルな計算機資源が不足している場合に，広域ネットワークやインターネット上の計算機資源を利用すること．
- 例: SETI@home（setiathome.berkeley.edu）は，世界のほぼすべての国で170万人以上のユーザーが利用しています．(2018年5月)

#### 潜在する並列ハードウェアの有効活用
- 最近のコンピュータは，ノートパソコンであっても，複数のプロセッサコアを持つ並列アーキテクチャになっています．
- 並列ソフトウェアは，マルチコア，マルチスレッドなどの並列ハードウェアに対応しています．
- ほとんどの場合，現代のコンピュータで実行されるシリアルプログラムは，潜在的な計算能力を「浪費」しています．

#### 未来
- この20年以上の間に，ネットワークの高速化，分散システム，マルチプロセッサコンピュータのアーキテクチャ（デスクトップレベルでも）が示すトレンドは，並列処理がコンピューティングの未来であることを明確に示しています．
- 同時期に，スーパーコンピュータの性能は50万倍以上に向上しており，現在も終わりは見えません．
- エクサスケール・コンピューティングに向けた競争はすでに始まっており，私たちはエクサスケールの時代に入っています．
- エクサフロップ ＝ 1秒間に10の18乗回の計算
- US DOEエクサスケールプロジェクト： [https:/www.exascaleproject.org](https:/www.exascaleproject.org)

## 誰が並列計算を使っているのか？
### 科学と工学
- 歴史的に，並列計算は「計算機のハイエンド」と考えられており，科学や工学の多くの分野で難しい問題のモデル化に使われてきました．
- 大気，地球，環境
- 物理学-応用，核，粒子，凝縮系，高圧，核融合，フォトニクス
- バイオサイエンス，バイオテクノロジー，遺伝学
- 化学，分子科学
- 地質学，地震学
- 機械工学 - 義肢装具から宇宙船まで
- 電気工学，回路設計，マイクロエレクトロニクス
- コンピュータサイエンス，数学
- 防衛，兵器

### 産業と商業
- 今日では，商用アプリケーションが，より高速なコンピュータを開発するための同等以上の原動力となっています．これらのアプリケーションでは，大量のデータを高度に処理することが求められています．例えば
- "ビッグデータ"，データベース，データマイニング
- 人工知能(AI)
- 石油探査
- ウェブ検索エンジン，ウェブベースのビジネスサービス
- 医療用画像処理，診断
- 医薬品設計
- 金融・経済モデリング
- 国内および多国籍企業の経営
- エンタテインメント業界を中心とした高度なグラフィックスとバーチャルリアリティ
- ネットワークビデオおよびマルチメディア技術
- コラボレーションワーク環境

### グルーバルアプリケーション
- 並列コンピューティングは，現在，世界中で様々なアプリケーションに幅広く利用されています．

# コンセプトと用語
## フォン・ノイマン型コンピュータアーキテクチャ
![vonneumann2.jpeg](/philosophers/vonneumann2.jpeg)
John von Neumann circa 1940s
(Source: LANL archives)
- ハンガリーの数学者ジョン・フォン・ノイマンが1945年に発表した論文で，電子計算機の一般的な要件を初めて記述したことにちなんで名付けられました．
- ストアド・プログラム・コンピュータとも呼ばれ，プログラムの命令とデータの両方が電子メモリに保存されます．ハードワイヤリングによってプログラムされた初期のコンピュータとは異なります．
- これ以降，ほぼすべてのコンピュータがこの基本設計を踏襲しています．
![vonneumann1.gif](/philosophers/vonneumann1.gif)
- 4つの主要コンポーネントで構成されています．
  - メモリー
  - コントロールユニット
  - 演算ロジックユニット
  - 入力/出力
- 読み書き可能なランダムアクセスメモリーは，プログラム命令とデータの両方を格納するために使用されます．
- プログラム命令は，コンピュータに何かを指示するコード化されたデータです．
- データは，プログラムが使用するための単なる情報です．
- 制御ユニットは，メモリから命令やデータを取り出し，その命令をデコードし，プログラムされたタスクを達成するために操作を逐次調整します．
- 算術ユニットは，基本的な算術演算を行います．
- Input/Outputは，人間が操作するためのインターフェースです．

彼のその他の驚くべき業績については，[http://en.wikipedia.org/wiki/John_von_Neumann](http://en.wikipedia.org/wiki/John_von_Neumann) をご覧ください．
並列コンピュータは，この基本的なデザインを踏襲していますが，単位が倍になっただけです．基本となるアーキテクチャは同じです．

## フリンの古典的分類
- 並列コンピュータを分類する方法は様々です．参考文献にその例が掲載されています．
- 1966年から広く使われている分類の一つに「Flynnの分類法」というものがあります．
- フリンの分類法は，マルチプロセッサコンピュータのアーキテクチャを，「命令ストリーム」と「データストリーム」という2つの独立した次元に沿ってどのように分類できるかによって区別します．これらの次元は，それぞれ2つの可能な状態のうちの1つしかありません．「シングル」または「マルチ」です．
- 以下のマトリックスは，Flynn氏による4つの可能な分類を定義しています．
![flynnstaxonomy.gif](/philosophers/flynnstaxonomy.gif)

### 単一命令，単一データ (SISD)
- シリアル（非パラレル）コンピュータ
- 単一命令: 1つのクロックサイクル中に，1つの命令ストリームのみがCPUによって実行されます．
- 単一データ: 1クロックの間に，1つのデータストリームのみが入力として使用されます．
- 決定論的実行
- 最も古いタイプのコンピュータです．
- 例: 旧世代のメインフレーム，ミニコンピュータ，ワークステーション，シングルプロセッサ/コアPCなど．
![sisd2.gif](/philosophers/sisd2.gif)![sisd.gif](/philosophers/sisd.gif)

### 単一命令，複数データ (SIMD)
- 並列コンピュータの一種
- 単一命令: すべての処理ユニットが，任意のクロックサイクルで同じ命令を実行します．
- 複数データ: 各処理ユニットが異なるデータ要素を処理することができます．
- グラフィックスや画像処理など，規則性の高い特殊な問題に適しています．
- 同期実行（ロックステップ）と決定性実行
- 2種類あります．プロセッサーアレイとベクターパイプライン
- 例
  - プロセッサーアレイ: Thinking Machines CM-2, MasPar MP-1 & MP-2, ILLIAC IVなど．
  - ベクトルパイプライン: IBM 9000, Cray X-MP, Y-MP & C90, Fujitsu VP, NEC SX-2, Hitachi S820, ETA10
  - 最近のコンピュータ，特にGPU（Graphics Processor Unit）を搭載したコンピュータの多くは，SIMD命令と実行ユニットを採用しています．
![simd3.gif](/philosophers/simd3.gif)
![simd.gif](/philosophers/simd.gif)![simd2.gif](/philosophers/simd2.gif)

### 複数命令，単一データ (MISD)
- 並列コンピュータの一種
- 複数命令: 各処理ユニットが別々の命令ストリームを介して独立してデータを処理します．
- 単一データ: 1つのデータを複数の処理ユニットに入力します．
- このクラスの並列コンピュータは，実際にはほとんど存在しません．
- 想定される用途としては
  - 1つの信号ストリームに対して複数の周波数フィルタを動作させる
  - 1つのコード化されたメッセージを解読しようとする複数の暗号アルゴリズム
![misd4.gif](/philosophers/misd4.gif)![misd.gif](/philosophers/misd.gif)

### 複数命令，複数データ (MIMD)
- 並列コンピュータの一種
- 複数命令: すべてのプロセッサが異なる命令ストリームを実行している可能性があります．
- 複数データ: すべてのプロセッサが異なるデータストリームを扱う可能性があります．
- 実行には同期・非同期，決定論的・非決定論的があります．
- 現在，最も一般的な並列コンピュータのタイプであるスーパーコンピュータのほとんどがこのカテゴリーに属します．
- 例：最新のスーパーコンピュータ，ネットワーク接続された並列コンピュータクラスタや「グリッド」，マルチプロセッサSMPコンピュータ，マルチコアPCなど．
- なお，多くのMIMDアーキテクチャには，SIMD実行サブコンポーネントも含まれています．
![mimd2.gif](/philosophers/mimd2.gif)![mimd.gif](/philosophers/mimd.gif)

## 一般的な並列用語
- 他のすべてのものと同様に，並列コンピューティングにも独自の「専門用語」があります．並列コンピューティングに関連してよく使われる用語を以下に示します．
- これらのほとんどは，後ほど詳しく説明します．

### スーパーコンピューティング/ハイパフォーマンス・コンピューティング(HPC)
- 世界最速・最大のコンピュータを使って，大きな問題を解決します．

### ノード
- スタンドアロンの「箱入りコンピュータ」．通常，複数のCPUプロセッサコア，メモリ，ネットワークインターフェースなどで構成される．ノードをネットワークで接続してスーパーコンピュータを構成します．

### CPU/ソケット/プロセッサ/コア
- これは，人によって異なります．かつて，CPU（Central Processing Unit）は，コンピュータの単一の実行コンポーネントでした．その後，複数のCPUが1つのノードに組み込まれるようになりました．その後，個々のCPUは複数の「コア」に分割され，それぞれが固有の実行単位となりました．複数のコアを持つCPUは「ソケット」と呼ばれることもあるが，これはベンダーによって異なる．結果として，複数のコアを持つ複数のCPUを搭載したノードができあがります．この命名法は，時に混乱を招くことがあります．
![nodesocketcores.jpeg](/philosophers/nodesocketcores.jpeg)

### タスク
- 計算作業の論理的に分離した部分．タスクは通常，プロセッサで実行されるプログラムまたはプログラムに似た命令の集合体です．並列プログラムは，複数のプロセッサで実行される複数のタスクで構成されます．

### パイプライン処理
- 組立ラインのように入力を流しながら，タスクを異なるプロセッサユニットで実行するステップに分割する，並列コンピューティングの一種です．

### 共有メモリ
- ハードウェア的には，すべてのプロセッサが共通の物理メモリに直接（通常はバスベースで）アクセスできるコンピュータアーキテクチャのこと．
- プログラミング的には，並列タスクがすべて同じメモリの「絵」を持ち，物理メモリが実際にどこにあるかにかかわらず，同じ論理メモリの位置に直接アドレスしてアクセスできるモデルのことを指します．

### 対称型マルチプロセッシング (SMP)
- 複数のプロセッサが単一のアドレス空間を共有し，すべてのリソースに平等にアクセスできる共有メモリのハードウェア・アーキテクチャ．

### 分散メモリ
- ハードウェアでは，一般的ではない物理メモリに対するネットワークベースのメモリアクセスのこと．
- プログラミングモデルとしては，タスクは論理的にローカルマシンのメモリしか「見る」ことができず，他のタスクが実行されている他のマシンのメモリにアクセスするためには通信を使用しなければなりません．

### 通信 (コミュニケーション)
- 並列処理では，通常，データを交換する必要があります．これには，共有メモリバスやネットワークなど，いくつかの方法がありますが，どのような方法であっても，実際にデータを交換することを「通信」と呼びます．

### 同期
- 並列タスクをリアルタイムで調整することであり，通信と関連することが多い．多くの場合，アプリケーション内に同期ポイントを設け，他のタスクが同じポイントまたは論理的に同等のポイントに到達するまでタスクを続行できないようにします．
- 同期は通常，少なくとも1つのタスクの待ちを伴うため，並列アプリケーションのウォールクロック実行時間が長くなる原因となります．

### 粒度
- 並列計算機では，計算と通信の比率を示す定性的な指標として「粒度」が用いられます．
  - 粗粒度: 通信イベント間で比較的大きな計算処理が行われます．
  - 細粒度: 通信イベント間で比較的小さな計算処理が行われます．

### 観測されたスピードアップ
- 並列化されたコードの観察されたスピードアップは，次のように定義されます．
$$
\frac{直列実行のオールクロックタイム}{並列実行のウォールクロックタイム}
$$
- 並列プログラムの性能を示す最もシンプルで広く使われている指標の一つです．

### 並列オーバーヘッド
- 並列タスクを調整するために，有用な作業とは対照的に必要となる時間．並列オーバーヘッドには以下のような要素が含まれます．
  - タスク起動時間
  - 同期作業
  - データ通信
  - 並列言語，ライブラリ，OSなどによるソフトウェアのオーバーヘッド
  - タスク終了時間

### 超並列
- 並列システムを構成するハードウェアのことで，多数の処理要素を持つものを指します．「多数」の意味はどんどん増えていきますが，現在，最大の並列コンピュータは，数十万から数百万の処理要素で構成されています．

### 驚異的並列
- 似たような，しかし独立した多くのタスクを同時に解決し，タスク間の調整はほとんど必要ありません．
- 「(タスクの間に)依存性がなく，独立して並行で処理できる」というような意味です．

### スケーラビリティ
- 並列システム（ハードウェアおよびソフトウェア）において，リソースの追加に比例して並列処理速度が向上する能力を指す．スケーラビリティには以下のような要素があります．
  - ハードウェア-特にメモリ・CPUのバンド幅とネットワーク通信の特性
  - アプリケーションのアルゴリズム
  - 並列オーバーヘッド関連
  - 特定のアプリケーションの特性

## 並列プログラミングの限界とコスト
### アムダールの法則
- アムダールの法則とは，プログラムの潜在的なスピードアップは，並列化できるコードの割合（P）によって定義されるというものです．
$$
スピードアップ = \dfrac{1}{1-P}
$$
- 並列化できないコードがある場合は，$P = 0$，$スピードアップ = 1（スピードアップなし）$となります．
- すべてのコードが並列化されている場合，$P = 1$となり，スピードアップは無限大となります（理論上）．
- コードの50％が並列化できる場合，$最大スピードアップ＝2$となり，コードが2倍の速さで実行されることになります．
![amdahl1_0.gif](/philosophers/amdahl1_0.gif)
- 並列分数の作業を行うプロセッサの数を導入すると，その関係は次のようにモデル化できます．
$$
スピードアップ = \dfrac{1}{\dfrac{P}{N}+S}
$$
- ここで，P＝パラレルフラクション，N＝プロセッサ数，S＝シリアルフラクションです．
- 並列処理のスケーラビリティには限界があることはすぐにわかります．例えば

| | | |スピードアップ| |
| N       | P = .50 | P = .90 | P = .95 | P = .99 |
| -----   | ------- | ------- | ------- | ------- |
| 10      | 1.82    | 5.26    | 6.89    | 9.17    |
| 100     | 1.98    | 9.17    | 16.80   | 50.25   |
| 1,000   | 1.99    | 9.91    | 19.62   | 90.99   |
| 10,000  | 1.99    | 9.91    | 19.96   | 99.02   |
| 100,000 | 1.99    | 9.99    | 19.99   | 99.90   |
![amdahl2_0.gif](/philosophers/amdahl2_0.gif)
- "名言": 一生かけてコードの95%を並列化しても，どれだけプロセッサを投入しても20倍以上のスピードアップは達成できません．
- しかし，問題サイズを大きくすることで性能が向上する問題もあります．例えば，以下のようなものです．
```shell
	2D Grid Calculations
	Parallel fraction        85 seconds 85%
	Serial fraction          15 seconds   15%
```
- 問題サイズを大きくするには，グリッド次元を2倍にし，時間ステップを半分にします．これにより，格子点の数は4倍，時間ステップの数は2倍になります．そのときのタイムスケールは次のようになります．
```shell
	2D Grid Calculations
	Parallel fraction         680 seconds 97.84%
	Serial fraction           15 seconds    2.16%
```
- サイズに応じて並列時間の割合が増える問題は，並列時間の割合が固定されている問題よりもスケーラブルです．

### 複雑性
- 一般的に，並列アプリケーションは，対応するシリアルアプリケーションよりもはるかに複雑で，おそらく桁違いになります．複数の命令ストリームが同時に実行されるだけでなく，それらの間にデータが流れます．
- 複雑さに伴うコストは，ソフトウェア開発サイクルのほぼすべての局面で，プログラマの作業時間に換算されます．
  - 設計
  -コーディング
  -デバッグ
  -チューニング
  -メンテナンス
- 並列アプリケーションを扱う際には，「優れた」ソフトウェア開発手法を遵守することが重要です．特に，自分以外の誰かがそのソフトウェアを扱う必要がある場合はなおさらです．

### 移植性
- MPI，POSIXスレッド，OpenMPなど，いくつかのAPIの標準化により，並列プログラムの移植性の問題は，以前ほど深刻ではなくなりました．しかし...
- 直列プログラムに伴う移植性の問題は，すべて並列プログラムにも当てはまります．例えば，Fortran，C，C++のベンダーによる「拡張機能」を使用した場合，移植性が問題となります．
- いくつかのAPIに標準規格が存在していても，実装は様々な点で異なっており，移植性を高めるためにコードの修正が必要になることもあります．
- コードの移植性の問題では，オペレーティングシステムが重要な役割を果たします．
- ハードウェア・アーキテクチャは特徴的に変化が激しく，移植性に影響を与えます．

### リソース要件
- 並列プログラミングの主な目的は，実行ウォールクロック時間を短縮することですが，そのためにはより多くのCPU時間が必要となります．例えば，8つのプロセッサで1時間で実行される並列コードは，実際には8時間のCPU時間を使います．
- 並列コードでは，データを複製する必要があることや，並列サポートライブラリやサブシステムに関連するオーバーヘッドのため，直列コードよりも必要なメモリ量が多くなります．
- 短時間で実行される並列プログラムでは，同様の直列実装と比較して，実際に性能が低下することがあります．並列環境の構築，タスクの作成，通信，タスクの終了に伴うオーバーヘッドコストは，短時間の実行では総実行時間のかなりの部分を占めることがあります．

### スケーラビリティ
- 解決までの時間に応じて，強スケーリングと弱スケーリングの2種類があります．
- 強スケーリング
  - プロセッサーを追加しても，問題の合計サイズは固定されます．
  - 目標は，同じ問題サイズをより速く実行することです．
  - パーフェクトスケーリングとは，（直列計算と比較して）1Pの時間で問題が解けることを意味します．
- 弱スケーリング
  - プロセッサを追加しても，1プロセッサあたりの問題サイズは固定されます．問題サイズの合計は，使用するプロセッサの数に比例します．
  - 目標は，より大きな問題を同じ時間で実行することです．
  - パーフェクトスケーリングとは，問題Pxをシングルプロセッサで実行するのと同じ時間で実行することです．
![strongweakscaling.gif](/philosophers/strongweakscaling.gif)
- 並列プログラムのパフォーマンスのスケーリング能力は，いくつかの相互に関連する要因の結果です．単にプロセッサを増やすだけでは解決しません．
- アルゴリズムには，スケーラビリティに対する固有の限界がある可能性があります．リソースを追加すると，ある時点でパフォーマンスが低下します．これは，多くの並列アプリケーションに共通する状況です．
- スケーラビリティには，ハードウェアの要素が大きく影響します．例を挙げます．
  - SMPマシンにおけるメモリ-CPUバスの帯域幅
  - 通信ネットワークの帯域幅
  - 任意のマシンまたは複数のマシンで利用可能なメモリの量
  - プロセッサのクロック速度
- 並列サポートライブラリやサブシステムソフトウェアは，アプリケーションとは無関係にスケーラビリティを制限することがあります．

# 並列コンピュータのメモリアーキテクチャ
## 共有メモリ
### 一般的な特徴
- 共有メモリ並列コンピュータは，様々な種類があるが，共通しているのは，すべてのプロセッサがすべてのメモリをグローバルアドレス空間としてアクセスできることです．
- 複数のプロセッサが独立して動作し，同じメモリ資源を共有することができます．
- 1つのプロセッサが行ったメモリ位置の変更は，他のすべてのプロセッサにも反映されます．
- 歴史的には，共有メモリマシンは，メモリアクセス時間に基づいてUMAとNUMAに分類されてきました．

### ユニフォーム・メモリ・アクセス (UMA)
- 現在の主流は，SMP（Symmetric Multiprocessor）マシン．
- 同一のプロセッサーを搭載．
- メモリへのアクセスとアクセスタイムが等しい．
- CC-UMA（Cache Coherent UMA）と呼ばれることもある．キャッシュコヒーレントとは，あるプロセッサが共有メモリの場所を更新した場合，他のすべてのプロセッサがその更新を知ることができることを意味します．キャッシュコヒーレントは，ハードウェアレベルで実現されます．
![shared_mem.gif](/philosophers/shared_mem.gif)

### ノンユニフォーム・メモリ・アクセス (NUMA)
- 2台以上のSMPを物理的にリンクして作られることが多いです．
- あるSMPが他のSMPのメモリに直接アクセスできます．
- すべてのプロセッサがすべてのメモリに均等にアクセスできるわけではありません．
- リンク経由のメモリアクセスは遅くなる．
- キャッシュコヒーレンシーが保たれている場合は，CC-NUMA（Cache Coherent NUMA）と呼ばれることもあります．
![numa.gif](/philosophers/numa.gif)

### 利点
- グローバルアドレス空間は，メモリに対してユーザーフレンドリーなプログラミングの視点を提供します．
- メモリとCPUの距離が近いため，タスク間のデータ共有が高速かつ均一に行われます．

### 欠点
- 主な欠点は，メモリとCPUの間にスケーラビリティがないことです．CPUを追加すると，共有メモリ-CPU間のトラフィックが幾何学的に増加し，キャッシュコヒーレントシステムでは，キャッシュメモリの管理に関連するトラフィックが幾何学的に増加します．
- グローバルメモリへの "正しい "アクセスを保証する同期構造に対するプログラマの責任．

## 分散メモリ
### 一般的な特徴
- 分散型メモリシステムは，共有メモリシステムと同様に様々な種類がありますが，共通の特徴があります．分散メモリシステムでは，プロセッサ間のメモリを接続するための通信ネットワークが必要となります．
- プロセッサはそれぞれローカルメモリを持っています．あるプロセッサのメモリアドレスは他のプロセッサにマッピングされないため，すべてのプロセッサにまたがるグローバルアドレス空間という概念はありません．
- 各プロセッサは独自のローカルメモリを持っているため，独立して動作します．各プロセッサのローカルメモリを変更しても，他のプロセッサのメモリには影響を与えません．そのため，キャッシュコヒーレンシーの概念は適用されません．
- あるプロセッサが他のプロセッサのデータにアクセスする必要がある場合，データの通信方法やタイミングを明示的に定義するのは，通常，プログラマの仕事です．また，タスク間の同期もプログラマの責任です．
- データ転送に使用されるネットワーク「ファブリック」は，イーサネットのようなシンプルなものから，さまざまなものがあります．
![distributed_mem.gif](/philosophers/distributed_mem.gif)

### 利点
- メモリはプロセッサの数に応じてスケーラブルになります．プロセッサの数を増やすと，それに比例してメモリのサイズも大きくなります．
- 各プロセッサは，グローバルなキャッシュコヒーレンシーを維持するためのオーバーヘッドを必要とせず，干渉を受けずに自分のメモリに素早くアクセスすることができます．
- コストパフォーマンス: 既製のプロセッサやネットワークを利用できます．

### 欠点
- プロセッサ間のデータ通信に関する多くの詳細は，プログラマが担当します．
- グローバルメモリをベースにした既存のデータ構造を，このメモリ構成にマッピングするのは難しいかもしれません．
- メモリアクセス時間の不均一性: リモートノードに存在するデータは，ノードのローカルデータよりもアクセスに時間がかかります．

## ハイブリッド分散共有メモリ
### 一般的な特徴
- 現在，世界で最も大型で高速なコンピュータは，共有メモリと分散メモリの両方のアーキテクチャを採用しています．
![hybrid_mem.gif](/philosophers/hybrid_mem.gif)![hybrid_mem2.gif](/philosophers/hybrid_mem2.gif)
- 共有メモリコンポーネントは，共有メモリマシンやGPU（Graphics Processing Unit）であることもあります．
- 分散メモリとは，複数の共有メモリを持つGPUマシンをネットワーク化したもので，GPUマシンは自分のメモリしか知らず，他のマシンのメモリは知りません．そのため，あるマシンから別のマシンへデータを移動させるには，ネットワーク通信が必要となります．
- 現在のトレンドでは，このタイプのメモリアーキテクチャは，当面の間，コンピュータのハイエンドで普及・増加し続けると考えられます．

### 利点と欠点
- これは，共有メモリーと分散メモリーの両方のアーキテクチャーに共通するものです．
- スケーラビリティの向上は重要な利点です．
- プログラマの複雑さが増すことは重要なデメリットです．

# 並列プログラミングモデル
## 並列プログラミングモデルの概要
- 一般的に使用されている並列プログラミングモデルはいくつかあります．
  - 共有メモリ（スレッドなし）
  - スレッド
  - 分散メモリ/メッセージパッシング
  - データ並列
  - ハイブリッド
  - 単一プログラム複数データ（SPMD）
  - 複数プログラム複数データ（MPMD）
- 並列プログラミングモデルは，ハードウェアやメモリアーキテクチャの上に抽象化されて存在します．
- 意外に思われるかもしれませんが，これらのモデルは，特定の種類のマシンやメモリ・アーキテクチャに特化したものではありません．実際，これらのモデルは，（理論的には）どのようなハードウェアにも実装することができます．以下に，過去の事例を2つ紹介します．

### 分散型メモリマシンでの共有メモリモデル
- Kendall Square Research（KSR）のALLCACHEアプローチ．マシンメモリはネットワーク上のマシンに物理的に分散されているが，ユーザーには単一の共有メモリ・グローバルアドレス空間として見えます．一般的に，このアプローチは「仮想共有メモリ」と呼ばれています．
![modelabstraction1.gif](/philosophers/modelabstraction1.gif)

### 共有メモリマシンでの分散メモリモデル
- SGI Origin 2000では，MPI（Message Passing Interface）を採用しました．SGI Origin 2000は，CC-NUMAタイプの共有メモリ・アーキテクチャを採用しており，すべてのタスクは，すべてのマシンに広がるグローバル・アドレス空間に直接アクセスできます．しかし，分散型メモリマシンのネットワーク上で一般的に行われているMPIを使ったメッセージの送受信機能が実装されており，よく使われていました．
![modelabstraction2.gif](/philosophers/modelabstraction2.gif)

- どのモデルを使用するか？これは多くの場合，入手可能なものと個人的な選択の組み合わせです．最良のモデルはありませんが，あるモデルの実装が他のモデルよりも優れていることは確かです．
- 以下のセクションでは，上記の各モデルについて説明し，実際の実装例についても触れています．

## 共有メモリモデル（スレッドなし）
- このプログラミングモデルでは，プロセス・タスクは共通のアドレス空間を共有し，非同期に読み書きを行います．
- 共有メモリへのアクセスを制御し，競合を解決し，レースコンディションやデッドロックを防ぐために，ロック・セマフォなどのさまざまなメカニズムが使用されます．
- これは，おそらく最もシンプルな並列プログラミングモデルです．
- プログラマの視点から見たこのモデルの利点は，データの「所有権」という概念がないため，タスク間のデータ通信を明示的に指定する必要がないことです．すべてのプロセスが共有メモリを見て，同じようにアクセスできます．プログラムの開発が容易になります．
- 性能面での重要なデメリットは，データロカリティの理解と管理が難しくなることです．
  - データを処理するプロセスをローカルに置いておくことで，複数のプロセスが同じデータを使用する際に発生するメモリアクセス，キャッシュリフレッシュ，バストラフィックを節約することができます．
  - 残念ながら，データロカリティの制御は理解しがたく，一般ユーザーには手に負えないかもしれません．
![sharedmemorymodel.gif](/philosophers/sharedmemorymodel.gif)

### 実装
- スタンドアローンの共有メモリマシンでは，ネイティブのオペレーティングシステムやコンパイラ，ハードウェアが共有メモリプログラミングをサポートしています．例えば，POSIX規格では，共有メモリを使用するためのAPIが提供されており，UNIXでは共有メモリセグメント（shmget，shmat，shmctlなど）が提供されています．
- 分散型メモリマシンでは，メモリは物理的にはマシンのネットワークに分散していますが，専用のハードウェアとソフトウェアによってグローバル化されています．様々なSHMEMの実装があります: [http:/en.wikipedia.orgwikiSHMEM](http:/en.wikipedia.orgwikiSHMEM).

## スレッドモデル
- このプログラミングモデルは，共有メモリプログラミングの一種です．
- 並列プログラミングのスレッドモデルでは，1つの「重量級」のプロセスが，複数の「軽量級」の同時実行パスを持つことができます．
- 例:
  - メインプログラムであるa.outは，ネイティブOSによって実行がスケジューリングされます．a.outは，実行に必要なシステムリソースとユーザーリソースのすべてをロードして取得します．これが「重量級」のプロセスです．
  - a.outは，いくつかの連続した作業を行った後，オペレーティング・システムによってスケジュールされ，同時に実行できるいくつかのタスク（スレッド）を作成します．
  - 各スレッドはローカルデータを持ちますが，同時にa.outのリソース全体を共有します．これにより，各スレッドにプログラムのリソースを複製することに伴うオーバーヘッドが削減されます（「軽量級」）．また，各スレッドはa.outのメモリ空間を共有しているため，グローバルなメモリビューの恩恵を受けることができます．
  - スレッドの作業は，メインプログラムの中のサブルーチンと表現するのが最も適切でしょう．どのスレッドも，他のスレッドと同時にサブルーチンを実行することができます．
  - スレッドは，グローバルメモリを介して相互に通信します（アドレス位置の更新）．このため，複数のスレッドが同じグローバルアドレスを更新しないようにするための同期構造が必要となります．
  - スレッドの行き来は可能ですが，アプリケーションが完了するまで，必要な共有リソースを提供するためにa.outは存在し続けます．
![threadsmodel2.gif](/philosophers/threadsmodel2.gif)

### 実装
- プログラミングの観点から見ると，スレッドの実装は，一般的に以下のように構成されます．
  - 並列ソースコードの中から呼び出されるサブルーチンのライブラリ
  - 直列または並列のソースコードに埋め込まれたコンパイラ指示文のセット
- どちらの場合も，並列性の判断はプログラマが行います（ただし，コンパイラが助けてくれる場合もあります）．
- スレッドの実装は，コンピュータの世界では新しいものではありません．これまでは，ハードウェアベンダーが独自に開発したスレッドを実装していました．これらの実装は互いに大きく異なっていたため，プログラマが移植可能なスレッドアプリケーションを開発するのは困難でした．
- 関連性のない標準化の努力の結果，2つの全く異なるスレッドの実装が生まれました．POSIX ThreadsとOpenMPです．

### POSIXスレッド
- IEEE POSIX 1003.1c規格（1995年）で規定されています．C言語のみ．
- UnixLinux オペレーティングシステムの一部です．
- ライブラリベースです．
- 一般にPthreadsと呼ばれています．
- 非常に明示的な並列処理を行うため，プログラマは細部にまで注意を払う必要があります．

### OPENMP
- コンピュータのハードウェアおよびソフトウェアの主要ベンダー，組織，個人が共同で定義し，承認した業界標準規格．
- コンパイラの指示に基づきます．
- UnixおよびWindowsプラットフォームを含むマルチプラットフォームに対応しています．
- C/C++とFortranの実装が可能です．
- 非常に簡単でシンプルに使用できる-「インクリメンタルな並列化」を実現．直列コードから始められます．
- 他のスレッド実装も一般的ですが，ここでは説明しません．
  - Microsoftスレッド
  - Java, Pythonスレッド
  - GPU用CUDAスレッド

### 詳細情報
- POSIXスレッドチュートリアル: [https://hpc-tutorials.llnl.gov/posix](https://hpc-tutorials.llnl.gov/posix)
- OpenMPチュートリアル: [https://hpc.llnl.gov/openmp-tutorial](https://hpc.llnl.gov/openmp-tutorial)

## 分散メモリ/メッセージパッシングモデル
- このモデルは以下のような特徴を持っています．
  - 計算中にそれぞれのローカルメモリを使用するタスクの集合体．複数のタスクは，同じ物理マシンに存在することも，任意の数のマシンに存在することもできます．
  - タスクは，メッセージを送受信することで，通信によるデータのやり取りを行います．
  - データ転送には，通常，各プロセスで実行される協調動作が必要です．例えば，送信操作には，それに対応する受信操作が必要となります．
![msg_pass_model.gif](/philosophers/msg_pass_model.gif)

### 実装
- プログラミングの観点から見ると，メッセージパッシングの実装は，通常，サブルーチンのライブラリで構成されています．これらのサブルーチンへの呼び出しは，ソースコードに組み込まれています．並列性の判断はプログラマが行います．
- 1980年代以降，様々なメッセージパッシングライブラリが登場しました．これらの実装は互いに大きく異なっており，プログラマがポータブルなアプリケーションを開発することは困難でした．
- 1992年，メッセージパッシング実装のための標準的なインターフェースを確立することを主な目的として，MPIフォーラムが設立されました．
- MPI（Message Passing Interface）は，1994年にPart1が発表されました．その後，1996年にパート2（MPI-2），2012年にMPI-3がリリースされました．すべてのMPI仕様書はウェブ上で公開されています（[http:/www.mpi-forum.orgdocs](http:/www.mpi-forum.orgdocs)）．
- MPIは，メッセージパッシングの "デファクト "ともいえる業界標準であり，実業界で使用されている他のすべてのメッセージパッシングの実装に取って代わるものです．MPIの実装は，一般的な並列コンピューティング・プラットフォームのほぼすべてに対応しています．すべての実装がMPI-1，MPI-2，MPI-3のすべてを含んでいるわけではありません．

### 詳細情報
- MPIチュートリアル: [https://hpc-tutorials.llnl.gov/mpi](https://hpc-tutorials.llnl.gov/mpi)

## データ並列モデル
- PGAS（Partitioned Global Address Space）モデルと呼ばれることもあります．
- データ並列モデルには，以下のような特徴があります．
  - アドレス空間をグローバルに扱います．
  - 並列処理の多くは，データセットに対する操作を中心に行われます．データセットは通常，配列やキューブなどの共通構造に整理されています．
  - 一連のタスクは同じデータ構造上でまとめて作業しますが，各タスクは同じデータ構造の異なるパーティション上で作業します．
  - タスクは，例えば「すべての配列要素に4を加える」というように，作業のパーティションに対して同じ操作を行います．
- 共有メモリアーキテクチャでは，すべてのタスクがグローバルメモリを通じてデータ構造にアクセスできる場合があります．
- 分散メモリアーキテクチャでは，グローバルデータ構造を論理的または物理的に分割してタスクに割り当てることができます．
![data_parallel_model.gif](/philosophers/data_parallel_model.gif)

### 実装
- 現在，データ並列PGASモデルに基づく並列プログラミングの実装は，比較的人気があり，時には発展的なものもあります．
- Coarray Fortran: SPMD並列プログラミングのためのFortran 95の小さな拡張セットです．コンパイラに依存します．詳細情報: [https:/en.wikipedia.orgwikiCoarray_Fortran](https:/en.wikipedia.orgwikiCoarray_Fortran)
- Unified Parallel C (UPC): SPMD並列プログラミングのためのC言語の拡張．コンパイラに依存します．詳細はこちら: [https:/upc.lbl.gov](https:/upc.lbl.gov)
- Global Arrays: 分散型配列データ構造のコンテキストで共有メモリスタイルのプログラミング環境を提供します．パブリックドメインのライブラリで，CとFortran77に対応しています．詳細情報: [https:/en.wikipedia.orgwikiGlobal_Arrays](https:/en.wikipedia.orgwikiGlobal_Arrays)
- X10: IBMがThomas J. Watson Research Centerで開発しているPGASベースの並列プログラミング言語です．詳細はこちら: [http:/x10-lang.org](http:/x10-lang.org)
- Chapel: Cray社が中心となって進めているオープンソースの並列プログラミング言語プロジェクト．詳細はこちら: [http:/chapel.cray.com](http:/chapel.cray.com)

## ハイブリッドモデル
- ハイブリッドモデルは，これまでに説明したプログラミングモデルのうち，2つ以上のモデルを組み合わせたものです．
- 現在，ハイブリッドモデルの一般的な例は，メッセージパッシングモデル（MPI）とスレッドモデル（OpenMP）を組み合わせたものです．
  - スレッドは，ノード上のローカルデータを使用して，計算量の多いカーネルを実行します．
  - 異なるノード上のプロセス間の通信は，MPIを用いてネットワーク上で行われます．
- このハイブリッドモデルは，現在最も普及しているハードウェア環境である，クラスター化されたマルチマニーコアマシンに適しています．
- また，MPIとCPU-GPU(Graphics Processing Unit)を組み合わせたハイブリッドモデルも人気を集めています．
  - MPIタスクは，CPU上でローカルメモリを使用して実行され，ネットワークを介して相互に通信します．
  - 計算量の多いカーネルは，ノード上のGPUにオフロードされます．
  - ノード・ローカルメモリとGPUの間のデータ交換にはCUDA（または同等のもの）を使用します．
- その他のハイブリッドモデルも一般的です．
  - PthreadsとMPI
  - GPU以外のアクセラレータとMPI
  - ...
![hybrid_model.gif](/philosophers/hybrid_model.gif)![hybrid_model2.gif](/philosophers/hybrid_model2.gif)

## SPMDとMPMD
### 単一プログラム複数データ（SPMD）
- SPMDは，これまでに紹介した並列プログラミングモデルを自由に組み合わせて構築できる「高レベル」のプログラミングモデルです．
- 単一プログラム: すべてのタスクは，同じプログラムのコピーを同時に実行します．このプログラムは，スレッド，メッセージパッシング，データ並列，ハイブリッドのいずれかです．
- 複数データ: すべてのタスクが異なるデータを使用する可能性があります．
- SPMDのプログラムは，通常，タスクがプログラムの一部だけを分岐したり，条件付きで実行したりするために必要なロジックが組み込まれています．つまり，タスクは必ずしもプログラム全体を実行する必要はなく，プログラムの一部を実行するだけでよいのです．
- メッセージパッシングやハイブリッドプログラミングを用いたSPMDモデルは，マルチノードクラスタで最もよく使われる並列プログラミングモデルでしょう．
![spmd_model.gif](/philosophers/spmd_model.gif)

### 複数プログラム複数データ（MPMD）
- SPMDと同様に，MPMDも「高レベル」のプログラミングモデルであり，先に述べた並列プログラミングモデルの任意の組み合わせの上に構築することができます．
- 複数プログラム: タスクは異なるプログラムを同時に実行することがあります．プログラムには，スレッド，メッセージパッシング，データ並列，ハイブリッドなどがあります．
- 複数データー: すべてのタスクが異なるデータを使用する可能性があります．
- MPMDアプリケーションはSPMDアプリケーションほど一般的ではありませんが，ある種の問題，特にドメイン分解よりも関数分解に適した問題には適しているかもしれません（後述の「パーティショニング」で説明します）．
![mpmd_model.gif](/philosophers/mpmd_model.gif)

# 並列プログラムの設計
## 自動並列化と手動並列化
- 並列プログラムの設計・開発は，これまで非常に手作業の多い作業でした．並列性を見極めるのも，実際に実装するのも，すべてプログラマの責任です．
- 多くの場合，手動で並列コードを開発することは，時間がかかり，複雑で，エラーが発生しやすく，反復的なプロセスとなります．
- 数年前から，プログラマが直列プログラムを並列プログラムに変換するための様々なツールが登場しています．直列プログラムを自動的に並列化するツールとして最も一般的なのは，並列化コンパイラやプリプロセッサです．
- 並列化コンパイラは，一般的に2つの異なる方法で動作します．

### 完全自動化
- コンパイラはソースコードを解析し，並列化の機会を特定します．
- 分析には，並列化の阻害要因の特定や，場合によっては，その並列化によって実際に性能が向上するかどうかのコストの重み付けも含まれます．
- 自動並列化の対象として最も多いのがループ（do，for）です．

### プログラマによる管理
- プログラマは「コンパイラディレクティブ」または「コンパイラフラグ」を用いて，どのようにコードを並列化するかをコンパイラに明示的に伝えます．
- ある程度の自動並列化と組み合わせて使えるかもしれません．
- 最も一般的なコンパイラによる並列化は，オンノードの共有メモリとスレッド（OpenMPなど）を用いて行われます．
- 既存の直列コードから始めて，時間や予算に制約がある場合は，自動並列化が解決策になるかもしれません．ただし，自動並列化にはいくつかの重要な注意点があります．
  - 誤った結果を生む可能性があります．
  - 実際にパフォーマンスが低下する可能性があります．
  - 手動による並列化に比べて柔軟性が低いです．
  - コードのサブセット（主にループ）に限定されます．
  - コンパイラの解析で阻害要因があると判断された場合や，コードが複雑すぎる場合は，実際には並列化できないこともあります．
- このセクションでは，手動でパラレルコードを作成する方法について説明します．

## 問題とプログラムの理解
- 並列ソフトウェアを開発するための最初のステップは，並列で解決したい問題を理解することであることは言うまでもありません．直列プログラムから始めるのであれば，既存のコードも理解する必要があるでしょう．
- 問題の並列化に時間をかける前に，その問題が実際に並列化できるものかどうかを判断します．
- 並列化しやすい問題の例
  - 分子の独立した数千のコンフォーメーションのそれぞれのポテンシャルエネルギーを計算する．計算が終わったら，最小エネルギーのコンフォーメーションを見つけてください．
  - この問題は並行して解くことができます．それぞれの分子コンフォーメーションは独立して決定することができます．また，最小エネルギーコンフォメーションの計算も並列可能な問題です．
- 並列性がほとんどない問題の例
  - フィボナッチ級数（$0,1,1,2,3,5,8,13,21,...$）を公式を用いて計算すること． $F(n)=F(n-1)+F(n-2)$
  - $F(n)$の値の計算は，$F(n-1)$と$F(n-2)$の値を使用しており，先に計算しておく必要があります．
- プログラムのホットスポットを特定します．
  - 本当の仕事がどこで行われているかを知る必要があります．科学技術プログラムの大半は，通常，数カ所でほとんどの仕事を成し遂げています．
  - ここでは，プロファイラやパフォーマンス分析ツールが役立ちます．
  - ホットスポットの並列化に注力し，CPU使用率の低いプログラム部分は無視します．
- プログラムのボトルネックを特定します．
  - 不釣り合いに遅い部分や，並列化可能な作業を停止させたり，延期させたりする部分はありませんか？例えば，プログラムを遅くするものとして，IOがあります．
  - プログラムを再構築したり，別のアルゴリズムを使用することで，不要な低速部分を削減・除去できる可能性があります．
- 並列化の阻害要因を特定します．一般的な阻害要因の1つは，上のフィボナッチ数列で示されているように，データ依存性です．
- 可能であれば他のアルゴリズムを検討します．これは，並列アプリケーションを設計する際に最も重要な検討事項となるでしょう．
- 最適化されたサードパーティの並列ソフトウェアや，主要ベンダーが提供する高度に最適化された数学ライブラリ（IBMのESSL，IntelのMKL，AMDのAMCLなど）を活用できます．

## パーティショニング
- 並列プログラムを設計するための最初のステップは，問題を複数のタスクに分散できるような個別の作業「チャンク」に分割することです．これを「分解」または「パーティショニング」といいます．
- 並列タスクの間で計算作業を分割するには，ドメイン分割と機能分割という2つの基本的な方法があります．

### ドメイン分割
- このタイプのパーティショニングでは，問題に関連するデータを分解します．各並列タスクはそのデータの一部を処理します．
![domain_decomp.gif](/philosophers/domain_decomp.gif)
- データを分割する方法はさまざまです．
![distributions.gif](/philosophers/distributions.gif)

### 機能分割
- このアプローチでは，計算によって操作されるデータではなく，実行されるべき計算に焦点を当てます．問題は，行わなければならない作業に応じて分解されます．各タスクは，全体の作業の一部を実行します．
![functional_decomp.gif](/philosophers/functional_decomp.gif)
- 機能分解は，さまざまなタスクに分割できる問題に適しています．例えば

#### 生態系モデリング
- 各プログラムは与えられたグループの人口を計算し，各グループの成長は隣のグループの成長に依存します．時間が経過すると，各プロセスは現在の状態を計算し，次に隣接する集団と情報を交換します．その後，すべてのタスクは次の時間ステップでの状態を計算するために進行します．
![functional_ex1.gif](/philosophers/functional_ex1.gif)

#### 信号処理
- オーディオ信号のデータセットは，4つの異なる計算フィルターを通過します．それぞれのフィルターは独立したプロセスです．最初のデータセグメントは，最初のフィルターを通過してから2番目のフィルターに進みます．2番目のセグメントのデータが1番目のフィルターを通過すると，2番目のセグメントのデータも1番目のフィルターを通過します．4つ目のデータセグメントが最初のフィルターを通過するまでに，4つのタスクはすべてビジー状態になります．
![functional_ex2.gif](/philosophers/functional_ex2.gif)

#### 気候モデル
- 各モデルのコンポーネントは，それぞれ別のタスクと考えることができます．矢印は，計算中のコンポーネント間のデータ交換を表しています．大気モデルが風速データを生成して海洋モデルが使用し，海洋モデルが海面温度データを生成して大気モデルが使用する，といった具合です．
- この2つのタイプの問題分解を組み合わせることは，一般的で自然なことです．
![functional_ex3.gif](/philosophers/functional_ex3.gif)
![climatemodelling.png](/philosophers/climatemodelling.png)

## 通信
### 通信が必要な場合とは？
- タスク間の通信の必要性は，お客様の問題によって異なります．

#### 通信が不必要な場合
- 問題の種類によっては，タスクがデータを共有する必要がほとんどなく，分解して並列に実行できるものがあります．このような問題は，ほとんど通信を必要としない「驚異的並列」と呼ばれます．
- 例えば，白黒画像のすべてのピクセルの色を反転させる必要がある画像処理作業があるとします．このような場合，画像データを複数のタスクに分散させ，それぞれのタスクが独立して作業を行うことができます．
![black2white.gif](/philosophers/black2white.gif)

#### 通信が必要な場合
- ほとんどの並列アプリケーションはそれほど単純ではなく，タスク同士がデータを共有する必要があります．
- 例えば，2次元の熱拡散問題では，隣接するデータを持つタスクが計算した温度をタスクが知る必要があります．隣接するデータの変更は，そのタスクのデータに直接影響を与えます．
![heat_partitioned.gif](/philosophers/heat_partitioned.gif)

### 考慮すべき点
- プログラムのインタータスク通信を設計する際には，いくつかの重要な要素があります．

#### 通信オーバーヘッド
- タスク間通信には，事実上，オーバーヘッドがつきものです．
- 演算に使用できるマシンサイクルやリソースが，データのパッケージ化や送信に使用されています．
- 通信では，タスク間の何らかの同期が必要になることが多く，その結果，タスクが仕事をせずに「待っている」時間が発生することがあります．
- 競合する通信トラフィックは，利用可能なネットワーク帯域を飽和させ，パフォーマンス問題をさらに悪化させます．

#### レイテンシVS帯域幅
- レイテンシとは，最小（0バイト）のメッセージをA地点からB地点に送るのにかかる時間のことで，一般的にはマイクロ秒で表されます．
- 帯域幅とは，単位時間あたりに通信可能なデータ量のこと．一般的にはメガバイト/秒，ギガバイト/秒で表されます．
- 小さなメッセージを多数送信すると，通信のオーバーヘッドの大半を占めるレイテンシが発生します．多くの場合，小さなメッセージを大きなメッセージにまとめて送信する方が効率的であり，その結果，有効な通信帯域を増やすことができます．

#### 通信の可視化
- メッセージパッシングモデルでは，通信は明示的に行われ，一般的には非常に見やすく，プログラマーのコントロール下にあります．
- データ並列モデルでは，特に分散メモリ型のアーキテクチャでは，通信はプログラマには透過的に行われます．タスク間通信がどのように行われているかをプログラマが正確に知ることができない場合もあります．

#### 同期通信VS非同期通信
- 同期通信では，データを共有しているタスク間で何らかの「ハンドシェイク」が必要となります．これは，プログラマがコードで明示的に構成する場合もあれば，プログラマが知らない低いレベルで行われる場合もあります．
- 同期通信は，通信が完了するまで他の作業を待つ必要があるため，しばしばブロック通信と呼ばれます．
- 非同期通信では，タスク同士が独立してデータを転送することができます．例えば，タスク1はメッセージを準備してタスク2に送信し，すぐに別の作業を開始することができます．タスク2が実際にデータを受け取るタイミングは関係ありません．
- 非同期通信は，通信中に他の作業を行うことができるため，ノンブロッキング通信と呼ばれることもあります．
- 非同期通信を利用する最大のメリットは，計算と通信を交互に行うことです．

#### 通信の範囲
- どのタスクが相互に通信しなければならないかを知ることは，並列コードの設計段階で重要です．以下に説明する2つのスコープは，どちらも同期または非同期に実装することができます．
- Point-to-point: 2つのタスクが含まれ，一方のタスクがデータの送信者として機能し，もう一方のタスクが受信者として機能します．
- コレクティブ: 2つ以上のタスク間でのデータ共有を含み，それらのタスクはしばしば共通のグループまたはコレクティブのメンバーとして指定されます．いくつかの一般的なバリエーションがあります（他にもあります）．
![collective_comm.gif](/philosophers/collective_comm.gif)

#### 通信の効率化
- 多くの場合，プログラマは通信のパフォーマンスに影響を与えるような選択肢を持っています．ここではそのいくつかを紹介します．
- あるモデルに対して，どのような実装を使用すべきか？メッセージパッシングモデルを例にとると，あるハードウェアプラットフォーム上では，あるMPI実装の方が他の実装よりも高速である場合があります．
- どのような通信操作を行うべきか？前述のように，非同期の通信操作はプログラム全体のパフォーマンスを向上させます．
- ネットワークファブリック: プラットフォームによって使用するネットワークが異なります．あるネットワークは他のネットワークよりも優れています．より高速なネットワークを持つプラットフォームを選択することも選択肢の一つです．

#### オーバーヘッドと複雑性
![helloworldparallelcallgraph.gif](/philosophers/helloworldparallelcallgraph.gif)
- 最後に，これは考慮すべきことのほんの一部に過ぎません．
