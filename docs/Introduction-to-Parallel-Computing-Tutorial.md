# 要約
このチュートリアルは，"Livermore Computing Getting Started "ワークショップの最初のチュートリアルです．このチュートリアルは，後続のチュートリアルへの導入として，並列コンピューティングという広範かつ広範なトピックの簡単な概要を提供することを目的としています．そのため，並列コンピューティングのごく基本的な部分をカバーしており，このテーマに慣れてきたばかりで，このワークショップの他のチュートリアルの1つ以上に参加する予定の人を対象としています．並列プログラミングを詳しく説明することは意図していませんが，それにはかなりの時間が必要となります．このチュートリアルでは，まず，並列コンピューティングとは何か，どのように使われるのか，という議論から始まり，続いて，並列コンピューティングに関連する概念や用語について説明します．続いて，並列メモリ・アーキテクチャとプログラミング・モデルのトピックを取り上げます．これらのトピックに続いて，並列プログラムの設計と実行に関する複雑な問題について，一連の実践的な議論が行われます．最後に，簡単なシリアル・プログラムを並列化するためのいくつかの例を挙げて締めくくります．また，参考文献も掲載していますので，自習にも最適です．

# 並列計算の概要
## 並列計算とは？
### 直列計算
従来，ソフトウェアは直列計算のために書かれてきました．
- 問題は離散的な一連の命令に分割されます．
- 命令は次々に実行される．
- 1台のプロセッサで実行される．
- どの時点でも1つの命令しか実行できない．
![serialproblem.gif](/philosophers/serialproblem.gif)
例
![serialproblem2.gif](/philosophers/serialproblem2.gif)

### 並列計算
並列計算とは，簡単に言えば，計算問題を解決するために複数の計算機資源を同時に使用することです．
- 問題は，同時に解くことができる個別のパーツに分割される．
- 各パーツはさらに一連の命令に分割されます．
- 各パーツの命令は，異なるプロセッサ上で同時に実行される．
- 全体的な制御調整メカニズムを採用する．
![parallelproblem.gif](/philosophers/parallelproblem.gif)
例
![parallelproblem2.gif](/philosophers/parallelproblem2.gif)

- 計算問題は以下のことが可能でなければなりません．
  - 同時に解くことができる個別の作業に分解されていること．
  - 複数のプログラム命令を任意のタイミングで実行できること．
  - 複数の計算資源を用いた方が，単一の計算資源を用いた場合よりも短時間で解けること．

- 計算機資源は，通常，以下のようなものです．
  - 複数のプロセッサコアを持つ1台のコンピュータ．
  - ネットワークで接続された任意の台数の計算機．

### 並列コンピュータ
- 今日，事実上すべてのスタンドアロンコンピュータは，ハードウェアの観点から並列化されています．
  - 複数の機能ユニット（L1キャッシュ，L2キャッシュ，ブランチ，プリフェッチ，デコード，浮動小数点，グラフィックスプロセッシング（GPU），整数など）．
  - 複数の実行ユニットコア
  - 複数のハードウェアスレッド
![bgqcomputechip.jpeg](/philosophers/bgqcomputechip.jpeg)
IBM BG/Q Compute Chip with 18 cores (PU) and 16 L2 Cache units (L2)

- ネットワークは，複数の独立したコンピュータ（ノード）を接続して，より大きな並列コンピュータ・クラスターを構成します．
![nodesnetwork.gif](/philosophers/nodesnetwork.gif)

- 例えば，下の図はLLNLの典型的な並列コンピュータクラスタを示しています．
  - 各計算ノードは，それ自体がマルチプロセッサの並列コンピュータです．
  - 複数の計算ノードが Infiniband ネットワークで結ばれています．
  - 同じくマルチプロセッサを搭載した特殊用途のノードは，他の目的に使用されます．
![parallelcomputer1.gif](/philosophers/parallelcomputer1.gif)

- 世界の大型並列コンピュータ（スーパーコンピュータ）の大半は，一握りの（ほとんど）有名ベンダーが製造するハードウェアのクラスターです．
Source: Top500.org

## 並列計算を使う理由
### 現実の世界は非常に複雑である
- 自然界では，多くの複雑で相互に関連した事象が，時間的な順序の中で，同時に起こっています．
- 直列計算と比較して，並列計算は，複雑な現実世界の現象をモデル化し，シミュレーションし，理解するのに適しています．
- 例えば，これらをシリアルでモデリングすることを想像してみてください．

### 主な理由
#### 時間とお金の節約
- 理論的には，より多くのリソースを投入することで，タスクの完了までの時間を短縮し，コストを削減することができます．
- 並列コンピュータは，安価な汎用部品で構成することができます．

#### より大きな，より複雑な問題を解決する
- 多くの問題は非常に大きく，複雑であるため，特にコンピュータのメモリが限られている場合には，シリアルプログラムで解決することは現実的ではなく，不可能です．
- 例: [グランドチャレンジ問題](https://en.wikipedia.org/wiki/Grand_Challenges)では，ペタフロップスやペタバイトのコンピューティングリソースが必要となります．
- 例: ウェブ検索エンジン毎秒数百万件のトランザクションを処理するデータベース．

#### 並行性の提供
- 1つのコンピュートリソースは，同時に1つのことしかできません．複数のコンピュートリソースは，同時に多くのことを行うことができます．
- 例: コラボレーションネットワークは，世界中の人々が "バーチャル"に集まり，仕事をすることができるグローバルな場を提供します．

#### 地域外のリソースを活用する
- ローカルな計算機資源が不足している場合に，広域ネットワークやインターネット上の計算機資源を利用すること．
- 例: SETI@home（setiathome.berkeley.edu）は，世界のほぼすべての国で170万人以上のユーザーが利用しています．(2018年5月)

#### 潜在する並列ハードウェアの有効活用
- 最近のコンピュータは，ノートパソコンであっても，複数のプロセッサコアを持つ並列アーキテクチャになっています．
- 並列ソフトウェアは，マルチコア，マルチスレッドなどの並列ハードウェアに対応しています．
- ほとんどの場合，現代のコンピュータで実行されるシリアルプログラムは，潜在的な計算能力を「浪費」しています．

#### 未来
- この20年以上の間に，ネットワークの高速化，分散システム，マルチプロセッサコンピュータのアーキテクチャ（デスクトップレベルでも）が示すトレンドは，並列処理がコンピューティングの未来であることを明確に示しています．
- 同時期に，スーパーコンピュータの性能は50万倍以上に向上しており，現在も終わりは見えません．
- エクサスケール・コンピューティングに向けた競争はすでに始まっており，私たちはエクサスケールの時代に入っています．
- エクサフロップ ＝ 1秒間に10の18乗回の計算
- US DOEエクサスケールプロジェクト： [https:/www.exascaleproject.org](https:/www.exascaleproject.org)

## 誰が並列計算を使っているのか？
### 科学と工学
- 歴史的に，並列計算は「計算機のハイエンド」と考えられており，科学や工学の多くの分野で難しい問題のモデル化に使われてきました．
- 大気，地球，環境
- 物理学-応用，核，粒子，凝縮系，高圧，核融合，フォトニクス
- バイオサイエンス，バイオテクノロジー，遺伝学
- 化学，分子科学
- 地質学，地震学
- 機械工学 - 義肢装具から宇宙船まで
- 電気工学，回路設計，マイクロエレクトロニクス
- コンピュータサイエンス，数学
- 防衛，兵器

### 産業と商業
- 今日では，商用アプリケーションが，より高速なコンピュータを開発するための同等以上の原動力となっています．これらのアプリケーションでは，大量のデータを高度に処理することが求められています．例えば
- "ビッグデータ"，データベース，データマイニング
- 人工知能(AI)
- 石油探査
- ウェブ検索エンジン，ウェブベースのビジネスサービス
- 医療用画像処理，診断
- 医薬品設計
- 金融・経済モデリング
- 国内および多国籍企業の経営
- エンタテインメント業界を中心とした高度なグラフィックスとバーチャルリアリティ
- ネットワークビデオおよびマルチメディア技術
- コラボレーションワーク環境

### グルーバルアプリケーション
- 並列コンピューティングは，現在，世界中で様々なアプリケーションに幅広く利用されています．

# コンセプトと用語
## フォン・ノイマン型コンピュータアーキテクチャ
![vonneumann2.jpeg](/philosophers/vonneumann2.jpeg)
John von Neumann circa 1940s
(Source: LANL archives)
- ハンガリーの数学者ジョン・フォン・ノイマンが1945年に発表した論文で，電子計算機の一般的な要件を初めて記述したことにちなんで名付けられました．
- ストアド・プログラム・コンピュータとも呼ばれ，プログラムの命令とデータの両方が電子メモリに保存されます．ハードワイヤリングによってプログラムされた初期のコンピュータとは異なります．
- これ以降，ほぼすべてのコンピュータがこの基本設計を踏襲しています．
![vonneumann1.gif](/philosophers/vonneumann1.gif)
- 4つの主要コンポーネントで構成されています．
  - メモリー
  - コントロールユニット
  - 演算ロジックユニット
  - 入力/出力
- 読み書き可能なランダムアクセスメモリーは，プログラム命令とデータの両方を格納するために使用されます．
- プログラム命令は，コンピュータに何かを指示するコード化されたデータです．
- データは，プログラムが使用するための単なる情報です．
- 制御ユニットは，メモリから命令やデータを取り出し，その命令をデコードし，プログラムされたタスクを達成するために操作を逐次調整します．
- 算術ユニットは，基本的な算術演算を行います．
- Input/Outputは，人間が操作するためのインターフェースです．

彼のその他の驚くべき業績については，[http://en.wikipedia.org/wiki/John_von_Neumann](http://en.wikipedia.org/wiki/John_von_Neumann) をご覧ください．
並列コンピュータは，この基本的なデザインを踏襲していますが，単位が倍になっただけです．基本となるアーキテクチャは同じです．

## フリンの古典的分類
- 並列コンピュータを分類する方法は様々です．参考文献にその例が掲載されています．
- 1966年から広く使われている分類の一つに「Flynnの分類法」というものがあります．
- フリンの分類法は，マルチプロセッサコンピュータのアーキテクチャを，「命令ストリーム」と「データストリーム」という2つの独立した次元に沿ってどのように分類できるかによって区別します．これらの次元は，それぞれ2つの可能な状態のうちの1つしかありません．「シングル」または「マルチ」です．
- 以下のマトリックスは，Flynn氏による4つの可能な分類を定義しています．
![flynnstaxonomy.gif](/philosophers/flynnstaxonomy.gif)

### 単一命令，単一データ (SISD)
- シリアル（非パラレル）コンピュータ
- 単一命令: 1つのクロックサイクル中に，1つの命令ストリームのみがCPUによって実行されます．
- 単一データ: 1クロックの間に，1つのデータストリームのみが入力として使用されます．
- 決定論的実行
- 最も古いタイプのコンピュータです．
- 例: 旧世代のメインフレーム，ミニコンピュータ，ワークステーション，シングルプロセッサ/コアPCなど．
![sisd2.gif](/philosophers/sisd2.gif)![sisd.gif](/philosophers/sisd.gif)

### 単一命令，複数データ (SIMD)
- 並列コンピュータの一種
- 単一命令: すべての処理ユニットが，任意のクロックサイクルで同じ命令を実行します．
- 複数データ: 各処理ユニットが異なるデータ要素を処理することができます．
- グラフィックスや画像処理など，規則性の高い特殊な問題に適しています．
- 同期実行（ロックステップ）と決定性実行
- 2種類あります．プロセッサーアレイとベクターパイプライン
- 例
  - プロセッサーアレイ: Thinking Machines CM-2, MasPar MP-1 & MP-2, ILLIAC IVなど．
  - ベクトルパイプライン: IBM 9000, Cray X-MP, Y-MP & C90, Fujitsu VP, NEC SX-2, Hitachi S820, ETA10
  - 最近のコンピュータ，特にGPU（Graphics Processor Unit）を搭載したコンピュータの多くは，SIMD命令と実行ユニットを採用しています．
![simd3.gif](/philosophers/simd3.gif)
![simd.gif](/philosophers/simd.gif)![simd2.gif](/philosophers/simd2.gif)

### 複数命令，単一データ (MISD)
- 並列コンピュータの一種
- 複数命令: 各処理ユニットが別々の命令ストリームを介して独立してデータを処理します．
- 単一データ: 1つのデータを複数の処理ユニットに入力します．
- このクラスの並列コンピュータは，実際にはほとんど存在しません．
- 想定される用途としては
  - 1つの信号ストリームに対して複数の周波数フィルタを動作させる
  - 1つのコード化されたメッセージを解読しようとする複数の暗号アルゴリズム
![misd4.gif](/philosophers/misd4.gif)![misd.gif](/philosophers/misd.gif)

### 複数命令，複数データ (MIMD)
- 並列コンピュータの一種
- 複数命令: すべてのプロセッサが異なる命令ストリームを実行している可能性があります．
- 複数データ: すべてのプロセッサが異なるデータストリームを扱う可能性があります．
- 実行には同期・非同期，決定論的・非決定論的があります．
- 現在，最も一般的な並列コンピュータのタイプであるスーパーコンピュータのほとんどがこのカテゴリーに属します．
- 例：最新のスーパーコンピュータ，ネットワーク接続された並列コンピュータクラスタや「グリッド」，マルチプロセッサSMPコンピュータ，マルチコアPCなど．
- なお，多くのMIMDアーキテクチャには，SIMD実行サブコンポーネントも含まれています．
![mimd2.gif](/philosophers/mimd2.gif)![mimd.gif](/philosophers/mimd.gif)

## 一般的な並列用語
- 他のすべてのものと同様に，並列コンピューティングにも独自の「専門用語」があります．並列コンピューティングに関連してよく使われる用語を以下に示します．
- これらのほとんどは，後ほど詳しく説明します．

### スーパーコンピューティング/ハイパフォーマンス・コンピューティング(HPC)
- 世界最速・最大のコンピュータを使って，大きな問題を解決します．

### ノード
- スタンドアロンの「箱入りコンピュータ」．通常，複数のCPUプロセッサコア，メモリ，ネットワークインターフェースなどで構成される．ノードをネットワークで接続してスーパーコンピュータを構成します．

### CPU/ソケット/プロセッサ/コア
- これは，人によって異なります．かつて，CPU（Central Processing Unit）は，コンピュータの単一の実行コンポーネントでした．その後，複数のCPUが1つのノードに組み込まれるようになりました．その後，個々のCPUは複数の「コア」に分割され，それぞれが固有の実行単位となりました．複数のコアを持つCPUは「ソケット」と呼ばれることもあるが，これはベンダーによって異なる．結果として，複数のコアを持つ複数のCPUを搭載したノードができあがります．この命名法は，時に混乱を招くことがあります．
![nodesocketcores.jpeg](/philosophers/nodesocketcores.jpeg)

### タスク
- 計算作業の論理的に分離した部分．タスクは通常，プロセッサで実行されるプログラムまたはプログラムに似た命令の集合体です．並列プログラムは，複数のプロセッサで実行される複数のタスクで構成されます．

### パイプライン処理
- 組立ラインのように入力を流しながら，タスクを異なるプロセッサユニットで実行するステップに分割する，並列コンピューティングの一種です．

### 共有メモリ
- ハードウェア的には，すべてのプロセッサが共通の物理メモリに直接（通常はバスベースで）アクセスできるコンピュータアーキテクチャのこと．
- プログラミング的には，並列タスクがすべて同じメモリの「絵」を持ち，物理メモリが実際にどこにあるかにかかわらず，同じ論理メモリの位置に直接アドレスしてアクセスできるモデルのことを指します．

### 対称型マルチプロセッシング (SMP)
- 複数のプロセッサが単一のアドレス空間を共有し，すべてのリソースに平等にアクセスできる共有メモリのハードウェア・アーキテクチャ．

### 分散メモリ
- ハードウェアでは，一般的ではない物理メモリに対するネットワークベースのメモリアクセスのこと．
- プログラミングモデルとしては，タスクは論理的にローカルマシンのメモリしか「見る」ことができず，他のタスクが実行されている他のマシンのメモリにアクセスするためには通信を使用しなければなりません．

### 通信 (コミュニケーション)
- 並列処理では，通常，データを交換する必要があります．これには，共有メモリバスやネットワークなど，いくつかの方法がありますが，どのような方法であっても，実際にデータを交換することを「通信」と呼びます．

### 同期
- 並列タスクをリアルタイムで調整することであり，通信と関連することが多い．多くの場合，アプリケーション内に同期ポイントを設け，他のタスクが同じポイントまたは論理的に同等のポイントに到達するまでタスクを続行できないようにします．
- 同期は通常，少なくとも1つのタスクの待ちを伴うため，並列アプリケーションのウォールクロック実行時間が長くなる原因となります．

### 粒度
- 並列計算機では，計算と通信の比率を示す定性的な指標として「粒度」が用いられます．
  - 粗粒度: 通信イベント間で比較的大きな計算処理が行われます．
  - 細粒度: 通信イベント間で比較的小さな計算処理が行われます．

### 観測されたスピードアップ
- 並列化されたコードの観察されたスピードアップは，次のように定義されます．
$$
\frac{直列実行のオールクロックタイム}{並列実行のウォールクロックタイム}
$$
- 並列プログラムの性能を示す最もシンプルで広く使われている指標の一つです．

### 並列オーバーヘッド
- 並列タスクを調整するために，有用な作業とは対照的に必要となる時間．並列オーバーヘッドには以下のような要素が含まれます．
  - タスク起動時間
  - 同期作業
  - データ通信
  - 並列言語，ライブラリ，OSなどによるソフトウェアのオーバーヘッド
  - タスク終了時間

### 超並列
- 並列システムを構成するハードウェアのことで，多数の処理要素を持つものを指します．「多数」の意味はどんどん増えていきますが，現在，最大の並列コンピュータは，数十万から数百万の処理要素で構成されています．

### 驚異的並列
- 似たような，しかし独立した多くのタスクを同時に解決し，タスク間の調整はほとんど必要ありません．
- 「(タスクの間に)依存性がなく，独立して並行で処理できる」というような意味です．

### スケーラビリティ
- 並列システム（ハードウェアおよびソフトウェア）において，リソースの追加に比例して並列処理速度が向上する能力を指す．スケーラビリティには以下のような要素があります．
  - ハードウェア-特にメモリ・CPUのバンド幅とネットワーク通信の特性
  - アプリケーションのアルゴリズム
  - 並列オーバーヘッド関連
  - 特定のアプリケーションの特性

## 並列プログラミングの限界とコスト
### アムダールの法則
- アムダールの法則とは，プログラムの潜在的なスピードアップは，並列化できるコードの割合（P）によって定義されるというものです．
$$
スピードアップ = \dfrac{1}{1-P}
$$
- 並列化できないコードがある場合は，$P = 0$，$スピードアップ = 1（スピードアップなし）$となります．
- すべてのコードが並列化されている場合，$P = 1$となり，スピードアップは無限大となります（理論上）．
- コードの50％が並列化できる場合，$最大スピードアップ＝2$となり，コードが2倍の速さで実行されることになります．
![amdahl1_0.gif](/philosophers/amdahl1_0.gif)
- 並列分数の作業を行うプロセッサの数を導入すると，その関係は次のようにモデル化できます．
$$
スピードアップ = \dfrac{1}{\dfrac{P}{N}+S}
$$
- ここで，P＝パラレルフラクション，N＝プロセッサ数，S＝シリアルフラクションです．
- 並列処理のスケーラビリティには限界があることはすぐにわかります．例えば

| | | |スピードアップ| |
| N       | P = .50 | P = .90 | P = .95 | P = .99 |
| -----   | ------- | ------- | ------- | ------- |
| 10      | 1.82    | 5.26    | 6.89    | 9.17    |
| 100     | 1.98    | 9.17    | 16.80   | 50.25   |
| 1,000   | 1.99    | 9.91    | 19.62   | 90.99   |
| 10,000  | 1.99    | 9.91    | 19.96   | 99.02   |
| 100,000 | 1.99    | 9.99    | 19.99   | 99.90   |
![amdahl2_0.gif](/philosophers/amdahl2_0.gif)
- "名言": 一生かけてコードの95%を並列化しても，どれだけプロセッサを投入しても20倍以上のスピードアップは達成できません．
- しかし，問題サイズを大きくすることで性能が向上する問題もあります．例えば，以下のようなものです．
```shell
	2D Grid Calculations
	Parallel fraction        85 seconds 85%
	Serial fraction          15 seconds   15%
```
- 問題サイズを大きくするには，グリッド次元を2倍にし，時間ステップを半分にします．これにより，格子点の数は4倍，時間ステップの数は2倍になります．そのときのタイムスケールは次のようになります．
```shell
	2D Grid Calculations
	Parallel fraction         680 seconds 97.84%
	Serial fraction           15 seconds    2.16%
```
- サイズに応じて並列時間の割合が増える問題は，並列時間の割合が固定されている問題よりもスケーラブルです．

### 複雑性
- 一般的に，並列アプリケーションは，対応するシリアルアプリケーションよりもはるかに複雑で，おそらく桁違いになります．複数の命令ストリームが同時に実行されるだけでなく，それらの間にデータが流れます．
- 複雑さに伴うコストは，ソフトウェア開発サイクルのほぼすべての局面で，プログラマの作業時間に換算されます．
  - 設計
  -コーディング
  -デバッグ
  -チューニング
  -メンテナンス
- 並列アプリケーションを扱う際には，「優れた」ソフトウェア開発手法を遵守することが重要です．特に，自分以外の誰かがそのソフトウェアを扱う必要がある場合はなおさらです．

### 移植性
- MPI，POSIXスレッド，OpenMPなど，いくつかのAPIの標準化により，並列プログラムの移植性の問題は，以前ほど深刻ではなくなりました．しかし...
- 直列プログラムに伴う移植性の問題は，すべて並列プログラムにも当てはまります．例えば，Fortran，C，C++のベンダーによる「拡張機能」を使用した場合，移植性が問題となります．
- いくつかのAPIに標準規格が存在していても，実装は様々な点で異なっており，移植性を高めるためにコードの修正が必要になることもあります．
- コードの移植性の問題では，オペレーティングシステムが重要な役割を果たします．
- ハードウェア・アーキテクチャは特徴的に変化が激しく，移植性に影響を与えます．

### リソース要件
- 並列プログラミングの主な目的は，実行ウォールクロック時間を短縮することですが，そのためにはより多くのCPU時間が必要となります．例えば，8つのプロセッサで1時間で実行される並列コードは，実際には8時間のCPU時間を使います．
- 並列コードでは，データを複製する必要があることや，並列サポートライブラリやサブシステムに関連するオーバーヘッドのため，直列コードよりも必要なメモリ量が多くなります．
- 短時間で実行される並列プログラムでは，同様の直列実装と比較して，実際に性能が低下することがあります．並列環境の構築，タスクの作成，通信，タスクの終了に伴うオーバーヘッドコストは，短時間の実行では総実行時間のかなりの部分を占めることがあります．

### スケーラビリティ
- 解決までの時間に応じて，強スケーリングと弱スケーリングの2種類があります．
- 強スケーリング
  - プロセッサーを追加しても，問題の合計サイズは固定されます．
  - 目標は，同じ問題サイズをより速く実行することです．
  - パーフェクトスケーリングとは，（直列計算と比較して）1Pの時間で問題が解けることを意味します．
- 弱スケーリング
  - プロセッサを追加しても，1プロセッサあたりの問題サイズは固定されます．問題サイズの合計は，使用するプロセッサの数に比例します．
  - 目標は，より大きな問題を同じ時間で実行することです．
  - パーフェクトスケーリングとは，問題Pxをシングルプロセッサで実行するのと同じ時間で実行することです．
![strongweakscaling.gif](/philosophers/strongweakscaling.gif)
- 並列プログラムのパフォーマンスのスケーリング能力は，いくつかの相互に関連する要因の結果です．単にプロセッサを増やすだけでは解決しません．
- アルゴリズムには，スケーラビリティに対する固有の限界がある可能性があります．リソースを追加すると，ある時点でパフォーマンスが低下します．これは，多くの並列アプリケーションに共通する状況です．
- スケーラビリティには，ハードウェアの要素が大きく影響します．例を挙げます．
  - SMPマシンにおけるメモリ-CPUバスの帯域幅
  - 通信ネットワークの帯域幅
  - 任意のマシンまたは複数のマシンで利用可能なメモリの量
  - プロセッサのクロック速度
- 並列サポートライブラリやサブシステムソフトウェアは，アプリケーションとは無関係にスケーラビリティを制限することがあります．

# 並列コンピュータのメモリアーキテクチャ
## 共有メモリ
### 一般的な特徴
- 共有メモリ並列コンピュータは，様々な種類があるが，共通しているのは，すべてのプロセッサがすべてのメモリをグローバルアドレス空間としてアクセスできることです．
- 複数のプロセッサが独立して動作し，同じメモリ資源を共有することができます．
- 1つのプロセッサが行ったメモリ位置の変更は，他のすべてのプロセッサにも反映されます．
- 歴史的には，共有メモリマシンは，メモリアクセス時間に基づいてUMAとNUMAに分類されてきました．

### ユニフォーム・メモリ・アクセス (UMA)
- 現在の主流は，SMP（Symmetric Multiprocessor）マシン．
- 同一のプロセッサーを搭載．
- メモリへのアクセスとアクセスタイムが等しい．
- CC-UMA（Cache Coherent UMA）と呼ばれることもある．キャッシュコヒーレントとは，あるプロセッサが共有メモリの場所を更新した場合，他のすべてのプロセッサがその更新を知ることができることを意味します．キャッシュコヒーレントは，ハードウェアレベルで実現されます．
![shared_mem.gif](/philosophers/shared_mem.gif)

### ノンユニフォーム・メモリ・アクセス (NUMA)
- 2台以上のSMPを物理的にリンクして作られることが多いです．
- あるSMPが他のSMPのメモリに直接アクセスできます．
- すべてのプロセッサがすべてのメモリに均等にアクセスできるわけではありません．
- リンク経由のメモリアクセスは遅くなる．
- キャッシュコヒーレンシーが保たれている場合は，CC-NUMA（Cache Coherent NUMA）と呼ばれることもあります．
![numa.gif](/philosophers/numa.gif)

### 利点
- グローバルアドレス空間は，メモリに対してユーザーフレンドリーなプログラミングの視点を提供します．
- メモリとCPUの距離が近いため，タスク間のデータ共有が高速かつ均一に行われます．

### 欠点
- 主な欠点は，メモリとCPUの間にスケーラビリティがないことです．CPUを追加すると，共有メモリ-CPU間のトラフィックが幾何学的に増加し，キャッシュコヒーレントシステムでは，キャッシュメモリの管理に関連するトラフィックが幾何学的に増加します．
- グローバルメモリへの "正しい "アクセスを保証する同期構造に対するプログラマの責任．

## 分散メモリ
### 一般的な特徴
- 分散型メモリシステムは，共有メモリシステムと同様に様々な種類がありますが，共通の特徴があります．分散メモリシステムでは，プロセッサ間のメモリを接続するための通信ネットワークが必要となります．
- プロセッサはそれぞれローカルメモリを持っています．あるプロセッサのメモリアドレスは他のプロセッサにマッピングされないため，すべてのプロセッサにまたがるグローバルアドレス空間という概念はありません．
- 各プロセッサは独自のローカルメモリを持っているため，独立して動作します．各プロセッサのローカルメモリを変更しても，他のプロセッサのメモリには影響を与えません．そのため，キャッシュコヒーレンシーの概念は適用されません．
- あるプロセッサが他のプロセッサのデータにアクセスする必要がある場合，データの通信方法やタイミングを明示的に定義するのは，通常，プログラマの仕事です．また，タスク間の同期もプログラマーの責任です．
- データ転送に使用されるネットワーク「ファブリック」は，イーサネットのようなシンプルなものから，さまざまなものがあります．
![distributed_mem.gif](/philosophers/distributed_mem.gif)

### 利点
- メモリはプロセッサの数に応じてスケーラブルになります．プロセッサの数を増やすと，それに比例してメモリのサイズも大きくなります．
- 各プロセッサは，グローバルなキャッシュコヒーレンシーを維持するためのオーバーヘッドを必要とせず，干渉を受けずに自分のメモリに素早くアクセスすることができます．
- コストパフォーマンス: 既製のプロセッサやネットワークを利用できます．

### 欠点
- プロセッサ間のデータ通信に関する多くの詳細は，プログラマが担当します．
- グローバルメモリをベースにした既存のデータ構造を，このメモリ構成にマッピングするのは難しいかもしれません．
- メモリアクセス時間の不均一性: リモートノードに存在するデータは，ノードのローカルデータよりもアクセスに時間がかかります．

## ハイブリッド分散共有メモリ
### 一般的な特徴
- 現在，世界で最も大型で高速なコンピュータは，共有メモリと分散メモリの両方のアーキテクチャを採用しています．
![hybrid_mem.gif](/philosophers/hybrid_mem.gif)![hybrid_mem2.gif](/philosophers/hybrid_mem2.gif)
- 共有メモリコンポーネントは，共有メモリマシンやGPU（Graphics Processing Unit）であることもあります．
- 分散メモリとは，複数の共有メモリを持つGPUマシンをネットワーク化したもので，GPUマシンは自分のメモリしか知らず，他のマシンのメモリは知りません．そのため，あるマシンから別のマシンへデータを移動させるには，ネットワーク通信が必要となります．
- 現在のトレンドでは，このタイプのメモリアーキテクチャは，当面の間，コンピュータのハイエンドで普及・増加し続けると考えられます．

### 利点と欠点
- これは，共有メモリーと分散メモリーの両方のアーキテクチャーに共通するものです．
- スケーラビリティの向上は重要な利点です．
- プログラマの複雑さが増すことは重要なデメリットです．

# 並列プログラミングモデル
## 並列プログラミングモデルの概要
- 一般的に使用されている並列プログラミングモデルはいくつかあります．
  - 共有メモリ（スレッドなし）
  - スレッド数
  - 分散メモリ メッセージパッシング
  - データ並列
  - ハイブリッド
  - シングル・プログラム・マルチプル・データ(SPMD)
  - マルチプル・プログラム・マルチプル・データ（MPMD
- 並列プログラミングモデルは，ハードウェアやメモリアーキテクチャの上に抽象化されて存在します．
- 意外に思われるかもしれませんが，これらのモデルは，特定の種類のマシンやメモリ・アーキテクチャに特化したものではありません．実際，これらのモデルは，（理論的には）どのようなハードウェアにも実装することができます．以下に，過去の事例を2つ紹介します．

### 分散型メモリマシンでの共有メモリモデル
- Kendall Square Research（KSR）のALLCACHEアプローチ．マシンメモリはネットワーク上のマシンに物理的に分散されているが，ユーザーには単一の共有メモリ・グローバルアドレス空間として見えます．一般的に，このアプローチは「仮想共有メモリ」と呼ばれています．
![modelabstraction1.gif](/philosophers/modelabstraction1.gif)

### 共有メモリマシンでの分散メモリモデル
- SGI Origin 2000では，MPI（Message Passing Interface）を採用しました．SGI Origin 2000は，CC-NUMAタイプの共有メモリ・アーキテクチャを採用しており，すべてのタスクは，すべてのマシンに広がるグローバル・アドレス空間に直接アクセスできます．しかし，分散型メモリマシンのネットワーク上で一般的に行われているMPIを使ったメッセージの送受信機能が実装されており，よく使われていました．
![modelabstraction2.gif](/philosophers/modelabstraction2.gif)

- どのモデルを使用するか？これは多くの場合，入手可能なものと個人的な選択の組み合わせです．最良のモデルはありませんが，あるモデルの実装が他のモデルよりも優れていることは確かです．
- 以下のセクションでは，上記の各モデルについて説明し，実際の実装例についても触れています．

## 共有メモリモデル（スレッドなし）
- このプログラミングモデルでは，プロセス・タスクは共通のアドレス空間を共有し，非同期に読み書きを行います．
- 共有メモリへのアクセスを制御し，競合を解決し，レースコンディションやデッドロックを防ぐために，ロック・セマフォなどのさまざまなメカニズムが使用されます．
- これは，おそらく最もシンプルな並列プログラミングモデルです．
- プログラマーの視点から見たこのモデルの利点は，データの「所有権」という概念がないため，タスク間のデータ通信を明示的に指定する必要がないことです．すべてのプロセスが共有メモリを見て，同じようにアクセスできます．プログラムの開発が容易になります．
- 性能面での重要なデメリットは，データロカリティの理解と管理が難しくなることです．
  - データを処理するプロセスをローカルに置いておくことで，複数のプロセスが同じデータを使用する際に発生するメモリアクセス，キャッシュリフレッシュ，バストラフィックを節約することができます．
  - 残念ながら，データロカリティの制御は理解しがたく，一般ユーザーには手に負えないかもしれません．
![sharedmemorymodel.gif](/philosophers/sharedmemorymodel.gif)

### 実装
- スタンドアローンの共有メモリマシンでは，ネイティブのオペレーティングシステムやコンパイラ，ハードウェアが共有メモリプログラミングをサポートしています．例えば，POSIX規格では，共有メモリを使用するためのAPIが提供されており，UNIXでは共有メモリセグメント（shmget，shmat，shmctlなど）が提供されています．
- 分散型メモリマシンでは，メモリは物理的にはマシンのネットワークに分散していますが，専用のハードウェアとソフトウェアによってグローバル化されています．様々なSHMEMの実装があります: [http:/en.wikipedia.orgwikiSHMEM](http:/en.wikipedia.orgwikiSHMEM).
